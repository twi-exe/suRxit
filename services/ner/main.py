# NER Service main.py
import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
import torch

app = FastAPI(title="NER Service", description="Extracts clinical entities from text using BioBERT.")

MODEL_NAME = os.getenv("MODEL_NAME", "dmis-lab/biobert-base-cased-v1.1")
ENTITY_LABELS = ["DRUG", "DOSAGE", "FREQ", "DISEASE", "ALLERGY"]

class NERRequest(BaseModel):
	text: str
	ingest_id: str

class Entity(BaseModel):
	span: List[int]
	type: str
	text: str
	confidence: float
	ingest_id: str

class NERResponse(BaseModel):
	entities: List[Entity]

# Load model and pipeline at startup
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)
ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")

@app.post("/ner/parse", response_model=NERResponse)
async def parse_ner(req: NERRequest):
	if not req.text:
		raise HTTPException(status_code=400, detail="Text is required.")
	try:
		results = ner_pipeline(req.text)
	except Exception as e:
		raise HTTPException(status_code=500, detail=f"NER model error: {e}")

	entities = []
	for ent in results:
		# Map entity label to clinical type if possible, else skip
		ent_type = ent.get('entity_group', ent.get('entity', ''))
		# For demo, allow all types, but in prod filter to ENTITY_LABELS
		entities.append(Entity(
			span=[ent['start'], ent['end']],
			type=ent_type,
			text=ent['word'],
			confidence=float(ent['score']),
			ingest_id=req.ingest_id
		))
	return {"entities": entities}
